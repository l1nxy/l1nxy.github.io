<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Rust Atomic 笔记 | linxy's blog</title><meta name=keywords content="rust"><meta name=description content="basic of rust concurrency
内部可变性是指可以通一个不可变引用来实现对内部数据的修改。标准库中有Cell<T>，Cell相当于持有这个Obj，要做修改只能先把T move出来再把T塞回去。RefCell<T>不但持有这个obj，还会维护一个引用计数，如果在运行时有多个Mut借用时，会panic。
RwLock是多线程版本的RefCell，但是多个可变借用时，或者说多个写时，会block住试图拿这个可变借用的线程，让它进入sleep。而Mutex不像Rwlock可以实现多个可读借用，mutex是彻底的独占的，其它线程都必须等待锁的释放。
UnSafeCell是实现内部可变性的关键类型，它只有get函数可以得到一个底层类型的raw pointer,UnsafeCell没有任何保证安全性的限制，需要用户自己来进行安全性的保证。一般不会直接用unsafe cell，都是包装成另一个类型来限制使用，比如实现成cell或者mutex。
Sendtrait意味着这个类型的所有权可以在线程之间转移，Synctrait意味着这个类型可以在线程之间共享。
一个struct如果所有的类型都是send和sync，那它本身也是send和sync的，如果要实现非send和sync的话，可以用phontomdata 标记类型。PhantomData用于标记Struct非sync，毕竟这是个zero sized type。
给一些非auto trait实现send和sync是unsafe的，因为取决于其中类型的具体实现，所以安全性需要自己来保证。
rust的mutex，实现了一个其它线程如果持有了mutex，但是panic了，这个mutex就是poison的机制：rust mutex doc。
mutex一些值得注意的点:


if let的scope。
if let Some(item) = list.lock().unwrap().pop() {//会lock到这个if结束
process_item(item);
}

    if list.lock().unwrap().pop() == Some(1) {//在进入body前，MutxGuard就已经drop掉了。
        do_something();
    }


rust 2024做出的一个if let的小修改，即if let的表达式生命周期不会延长到else body中去：rust 2024 doc


大多数的读写锁的实现都会block新的读者出现，当写者等待时，因为可能会多个读者共享导致写者一直要等待，这是读写锁中一个经典的饥饿问题。
## parking and condition variables
当一个线程在等待别的线程的通知的时候，这种叫thread parking，parking的时候，线程会进入睡眠，唤醒可以用unpark。
在实现上，unpark有一个很重要的特性是，有一个信号保留机制，即unpark在park之前执行了，这个park也不会让线程进入睡眠，因为消费者需要对生产者的每一个unpark都有响应，否则会有丢数据的风险。
但是unpark并不能叠加，所以unpark两次后，再Park两次还是会线程进入睡眠。
条件变量一般是与mutex结合使用，传入同一个mutex，一个线程wait，一个线程notify。如果两个线程在操作同一个条件变量但是不同的mutex，会引起panic.
Atomic and Memory order
原子类型可以在多线程间安全的访问和修改，但是依赖于Memory Ordering。比如最简单的order,Ralex,Relax只能保证单个变量的一致性，而多个变量间顺序无法保证。
atomic i32的溢出是回环的，不像普通的i32，溢出是会panic的。
为什么需要memory order?CPU会为了优化而把程序中的指令进行重排，写的是什么顺序，执行起来可能是别的顺序。
Happens before即保证A发生在B之前，但是在多线程中却是不一定的，使用锁可以保证，或者更严格的memory ordering。"><meta name=author content="linxy"><link rel=canonical href=https://linxy.dev/posts/rust-atomic/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://linxy.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://linxy.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://linxy.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://linxy.dev/apple-touch-icon.png><link rel=mask-icon href=https://linxy.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://linxy.dev/posts/rust-atomic/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://linxy.dev/posts/rust-atomic/"><meta property="og:site_name" content="linxy's blog"><meta property="og:title" content="Rust Atomic 笔记"><meta property="og:description" content="basic of rust concurrency 内部可变性是指可以通一个不可变引用来实现对内部数据的修改。标准库中有Cell<T>，Cell相当于持有这个Obj，要做修改只能先把T move出来再把T塞回去。RefCell<T>不但持有这个obj，还会维护一个引用计数，如果在运行时有多个Mut借用时，会panic。
RwLock是多线程版本的RefCell，但是多个可变借用时，或者说多个写时，会block住试图拿这个可变借用的线程，让它进入sleep。而Mutex不像Rwlock可以实现多个可读借用，mutex是彻底的独占的，其它线程都必须等待锁的释放。
UnSafeCell是实现内部可变性的关键类型，它只有get函数可以得到一个底层类型的raw pointer,UnsafeCell没有任何保证安全性的限制，需要用户自己来进行安全性的保证。一般不会直接用unsafe cell，都是包装成另一个类型来限制使用，比如实现成cell或者mutex。
Sendtrait意味着这个类型的所有权可以在线程之间转移，Synctrait意味着这个类型可以在线程之间共享。
一个struct如果所有的类型都是send和sync，那它本身也是send和sync的，如果要实现非send和sync的话，可以用phontomdata 标记类型。PhantomData用于标记Struct非sync，毕竟这是个zero sized type。
给一些非auto trait实现send和sync是unsafe的，因为取决于其中类型的具体实现，所以安全性需要自己来保证。
rust的mutex，实现了一个其它线程如果持有了mutex，但是panic了，这个mutex就是poison的机制：rust mutex doc。 mutex一些值得注意的点:
if let的scope。
if let Some(item) = list.lock().unwrap().pop() {//会lock到这个if结束 process_item(item); } if list.lock().unwrap().pop() == Some(1) {//在进入body前，MutxGuard就已经drop掉了。 do_something(); } rust 2024做出的一个if let的小修改，即if let的表达式生命周期不会延长到else body中去：rust 2024 doc
大多数的读写锁的实现都会block新的读者出现，当写者等待时，因为可能会多个读者共享导致写者一直要等待，这是读写锁中一个经典的饥饿问题。 ## parking and condition variables 当一个线程在等待别的线程的通知的时候，这种叫thread parking，parking的时候，线程会进入睡眠，唤醒可以用unpark。 在实现上，unpark有一个很重要的特性是，有一个信号保留机制，即unpark在park之前执行了，这个park也不会让线程进入睡眠，因为消费者需要对生产者的每一个unpark都有响应，否则会有丢数据的风险。 但是unpark并不能叠加，所以unpark两次后，再Park两次还是会线程进入睡眠。
条件变量一般是与mutex结合使用，传入同一个mutex，一个线程wait，一个线程notify。如果两个线程在操作同一个条件变量但是不同的mutex，会引起panic.
Atomic and Memory order 原子类型可以在多线程间安全的访问和修改，但是依赖于Memory Ordering。比如最简单的order,Ralex,Relax只能保证单个变量的一致性，而多个变量间顺序无法保证。 atomic i32的溢出是回环的，不像普通的i32，溢出是会panic的。 为什么需要memory order?CPU会为了优化而把程序中的指令进行重排，写的是什么顺序，执行起来可能是别的顺序。 Happens before即保证A发生在B之前，但是在多线程中却是不一定的，使用锁可以保证，或者更严格的memory ordering。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-10T17:25:14+08:00"><meta property="article:modified_time" content="2025-04-10T17:25:14+08:00"><meta property="article:tag" content="Rust"><meta property="og:image" content="https://linxy.dev/images/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://linxy.dev/images/papermod-cover.png"><meta name=twitter:title content="Rust Atomic 笔记"><meta name=twitter:description content="basic of rust concurrency
内部可变性是指可以通一个不可变引用来实现对内部数据的修改。标准库中有Cell<T>，Cell相当于持有这个Obj，要做修改只能先把T move出来再把T塞回去。RefCell<T>不但持有这个obj，还会维护一个引用计数，如果在运行时有多个Mut借用时，会panic。
RwLock是多线程版本的RefCell，但是多个可变借用时，或者说多个写时，会block住试图拿这个可变借用的线程，让它进入sleep。而Mutex不像Rwlock可以实现多个可读借用，mutex是彻底的独占的，其它线程都必须等待锁的释放。
UnSafeCell是实现内部可变性的关键类型，它只有get函数可以得到一个底层类型的raw pointer,UnsafeCell没有任何保证安全性的限制，需要用户自己来进行安全性的保证。一般不会直接用unsafe cell，都是包装成另一个类型来限制使用，比如实现成cell或者mutex。
Sendtrait意味着这个类型的所有权可以在线程之间转移，Synctrait意味着这个类型可以在线程之间共享。
一个struct如果所有的类型都是send和sync，那它本身也是send和sync的，如果要实现非send和sync的话，可以用phontomdata 标记类型。PhantomData用于标记Struct非sync，毕竟这是个zero sized type。
给一些非auto trait实现send和sync是unsafe的，因为取决于其中类型的具体实现，所以安全性需要自己来保证。
rust的mutex，实现了一个其它线程如果持有了mutex，但是panic了，这个mutex就是poison的机制：rust mutex doc。
mutex一些值得注意的点:


if let的scope。
if let Some(item) = list.lock().unwrap().pop() {//会lock到这个if结束
process_item(item);
}

    if list.lock().unwrap().pop() == Some(1) {//在进入body前，MutxGuard就已经drop掉了。
        do_something();
    }


rust 2024做出的一个if let的小修改，即if let的表达式生命周期不会延长到else body中去：rust 2024 doc


大多数的读写锁的实现都会block新的读者出现，当写者等待时，因为可能会多个读者共享导致写者一直要等待，这是读写锁中一个经典的饥饿问题。
## parking and condition variables
当一个线程在等待别的线程的通知的时候，这种叫thread parking，parking的时候，线程会进入睡眠，唤醒可以用unpark。
在实现上，unpark有一个很重要的特性是，有一个信号保留机制，即unpark在park之前执行了，这个park也不会让线程进入睡眠，因为消费者需要对生产者的每一个unpark都有响应，否则会有丢数据的风险。
但是unpark并不能叠加，所以unpark两次后，再Park两次还是会线程进入睡眠。
条件变量一般是与mutex结合使用，传入同一个mutex，一个线程wait，一个线程notify。如果两个线程在操作同一个条件变量但是不同的mutex，会引起panic.
Atomic and Memory order
原子类型可以在多线程间安全的访问和修改，但是依赖于Memory Ordering。比如最简单的order,Ralex,Relax只能保证单个变量的一致性，而多个变量间顺序无法保证。
atomic i32的溢出是回环的，不像普通的i32，溢出是会panic的。
为什么需要memory order?CPU会为了优化而把程序中的指令进行重排，写的是什么顺序，执行起来可能是别的顺序。
Happens before即保证A发生在B之前，但是在多线程中却是不一定的，使用锁可以保证，或者更严格的memory ordering。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://linxy.dev/posts/"},{"@type":"ListItem","position":2,"name":"Rust Atomic 笔记","item":"https://linxy.dev/posts/rust-atomic/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Rust Atomic 笔记","name":"Rust Atomic 笔记","description":"basic of rust concurrency 内部可变性是指可以通一个不可变引用来实现对内部数据的修改。标准库中有Cell\u0026lt;T\u0026gt;，Cell相当于持有这个Obj，要做修改只能先把T move出来再把T塞回去。RefCell\u0026lt;T\u0026gt;不但持有这个obj，还会维护一个引用计数，如果在运行时有多个Mut借用时，会panic。\nRwLock是多线程版本的RefCell，但是多个可变借用时，或者说多个写时，会block住试图拿这个可变借用的线程，让它进入sleep。而Mutex不像Rwlock可以实现多个可读借用，mutex是彻底的独占的，其它线程都必须等待锁的释放。\nUnSafeCell是实现内部可变性的关键类型，它只有get函数可以得到一个底层类型的raw pointer,UnsafeCell没有任何保证安全性的限制，需要用户自己来进行安全性的保证。一般不会直接用unsafe cell，都是包装成另一个类型来限制使用，比如实现成cell或者mutex。\nSendtrait意味着这个类型的所有权可以在线程之间转移，Synctrait意味着这个类型可以在线程之间共享。\n一个struct如果所有的类型都是send和sync，那它本身也是send和sync的，如果要实现非send和sync的话，可以用phontomdata 标记类型。PhantomData用于标记Struct非sync，毕竟这是个zero sized type。\n给一些非auto trait实现send和sync是unsafe的，因为取决于其中类型的具体实现，所以安全性需要自己来保证。\nrust的mutex，实现了一个其它线程如果持有了mutex，但是panic了，这个mutex就是poison的机制：rust mutex doc。 mutex一些值得注意的点:\nif let的scope。\nif let Some(item) = list.lock().unwrap().pop() {//会lock到这个if结束 process_item(item); } if list.lock().unwrap().pop() == Some(1) {//在进入body前，MutxGuard就已经drop掉了。 do_something(); } rust 2024做出的一个if let的小修改，即if let的表达式生命周期不会延长到else body中去：rust 2024 doc\n大多数的读写锁的实现都会block新的读者出现，当写者等待时，因为可能会多个读者共享导致写者一直要等待，这是读写锁中一个经典的饥饿问题。 ## parking and condition variables 当一个线程在等待别的线程的通知的时候，这种叫thread parking，parking的时候，线程会进入睡眠，唤醒可以用unpark。 在实现上，unpark有一个很重要的特性是，有一个信号保留机制，即unpark在park之前执行了，这个park也不会让线程进入睡眠，因为消费者需要对生产者的每一个unpark都有响应，否则会有丢数据的风险。 但是unpark并不能叠加，所以unpark两次后，再Park两次还是会线程进入睡眠。\n条件变量一般是与mutex结合使用，传入同一个mutex，一个线程wait，一个线程notify。如果两个线程在操作同一个条件变量但是不同的mutex，会引起panic.\nAtomic and Memory order 原子类型可以在多线程间安全的访问和修改，但是依赖于Memory Ordering。比如最简单的order,Ralex,Relax只能保证单个变量的一致性，而多个变量间顺序无法保证。 atomic i32的溢出是回环的，不像普通的i32，溢出是会panic的。 为什么需要memory order?CPU会为了优化而把程序中的指令进行重排，写的是什么顺序，执行起来可能是别的顺序。 Happens before即保证A发生在B之前，但是在多线程中却是不一定的，使用锁可以保证，或者更严格的memory ordering。\n","keywords":["rust"],"articleBody":"basic of rust concurrency 内部可变性是指可以通一个不可变引用来实现对内部数据的修改。标准库中有Cell，Cell相当于持有这个Obj，要做修改只能先把T move出来再把T塞回去。RefCell不但持有这个obj，还会维护一个引用计数，如果在运行时有多个Mut借用时，会panic。\nRwLock是多线程版本的RefCell，但是多个可变借用时，或者说多个写时，会block住试图拿这个可变借用的线程，让它进入sleep。而Mutex不像Rwlock可以实现多个可读借用，mutex是彻底的独占的，其它线程都必须等待锁的释放。\nUnSafeCell是实现内部可变性的关键类型，它只有get函数可以得到一个底层类型的raw pointer,UnsafeCell没有任何保证安全性的限制，需要用户自己来进行安全性的保证。一般不会直接用unsafe cell，都是包装成另一个类型来限制使用，比如实现成cell或者mutex。\nSendtrait意味着这个类型的所有权可以在线程之间转移，Synctrait意味着这个类型可以在线程之间共享。\n一个struct如果所有的类型都是send和sync，那它本身也是send和sync的，如果要实现非send和sync的话，可以用phontomdata 标记类型。PhantomData用于标记Struct非sync，毕竟这是个zero sized type。\n给一些非auto trait实现send和sync是unsafe的，因为取决于其中类型的具体实现，所以安全性需要自己来保证。\nrust的mutex，实现了一个其它线程如果持有了mutex，但是panic了，这个mutex就是poison的机制：rust mutex doc。 mutex一些值得注意的点:\nif let的scope。\nif let Some(item) = list.lock().unwrap().pop() {//会lock到这个if结束 process_item(item); } if list.lock().unwrap().pop() == Some(1) {//在进入body前，MutxGuard就已经drop掉了。 do_something(); } rust 2024做出的一个if let的小修改，即if let的表达式生命周期不会延长到else body中去：rust 2024 doc\n大多数的读写锁的实现都会block新的读者出现，当写者等待时，因为可能会多个读者共享导致写者一直要等待，这是读写锁中一个经典的饥饿问题。 ## parking and condition variables 当一个线程在等待别的线程的通知的时候，这种叫thread parking，parking的时候，线程会进入睡眠，唤醒可以用unpark。 在实现上，unpark有一个很重要的特性是，有一个信号保留机制，即unpark在park之前执行了，这个park也不会让线程进入睡眠，因为消费者需要对生产者的每一个unpark都有响应，否则会有丢数据的风险。 但是unpark并不能叠加，所以unpark两次后，再Park两次还是会线程进入睡眠。\n条件变量一般是与mutex结合使用，传入同一个mutex，一个线程wait，一个线程notify。如果两个线程在操作同一个条件变量但是不同的mutex，会引起panic.\nAtomic and Memory order 原子类型可以在多线程间安全的访问和修改，但是依赖于Memory Ordering。比如最简单的order,Ralex,Relax只能保证单个变量的一致性，而多个变量间顺序无法保证。 atomic i32的溢出是回环的，不像普通的i32，溢出是会panic的。 为什么需要memory order?CPU会为了优化而把程序中的指令进行重排，写的是什么顺序，执行起来可能是别的顺序。 Happens before即保证A发生在B之前，但是在多线程中却是不一定的，使用锁可以保证，或者更严格的memory ordering。\nRelax Relaxed Ordering保证了单个atomic变量的总修改顺序.\nRelaase and Acquire Release与Acquire是成对使用，release给store，acquire给load。acquire-load可以观测到所有的release-store的操作，可以保证所有的store都会发生在load之前。同时，还有一个两者的结合体，即AcqRel。\nconsume 只能说，load发生的时候，取决于这个值的读取操作，只能说store肯定发生于相关表达式求值这前，而非相关的肯定不会。但是实际上所有的CPU都是实现为relax，而编译器根本不支持这个操作。不会保证全局顺序的一致性。\nSeqCst SeqCst保证了所有的acquire ordering与release ordering，也保证了全局操作顺序的一致性。如果在乎性能可以使用 seqcst fence与relaxed ordering来代替。\n实际上release store可以分解成fence与relaxed ordering,因为fence会导致同步： 所有的store在release fence后面 会被acquire fence之前被观测到，即同步\nUnderstanding the processor 在x86和arm下，最低要求的Relaxed的load和store，与普通变量的读取与写入是一样的。（我觉得主要原因是x86是TSO，远大于Relaxed的同步要求，而arm这是默认最低水平的同步要求。） 但是如果是Read-Modify-Write这样的顺序的话，比如*x+=1，这样的语句，对于x86来说，只有一条mov，这样是原子的，但是对于arm来说，这是三条指令，这意味着它并不是原子的了。 普通的add并不是原子的，因为在cpu看到会拆成好多条微指令，所以并不是原子的，如果要实现原子性的add或者其它操作，需要用到x86下的lock 前缀。 在x86下，add,sub,and not or xor都支持lock前缀，当它们加上了lock前缀之后，会block住其它核心 ，之后会将结果同步给其它核心，以完成同步。 只有add有xadd指针，x意味首exchange；对于bit，可以用bts，btr，btc指令来实现，这些指令也可以加lock。 而compare and exchange有cmpxchg 指令，可以实现比较然后交换。\nload-linked and store-conditinal instructions 对于RISC架构来说，LL/SC loop是最接近cmp and exchange语义的。其中包含了两个基本指令，一个load，一个store-conditional。与普通的load store不一样的是，如果在store的时候，有其它线程在load-link指令后写入内存，store会拒绝写入。 用这两个指令，可以实现读取，修改，写入，如果中间因为别的线程有修改写入失败了，则重试即可。 在x86用fetch等指令，可以生成与compare and exchange相同的指令，但是在arm上并不一定，这种优化实际上很难做，因为ll store中间能插的指令过少\ncache MESI的四个状态，modified：包含了本cach line修改了但是没有写回主存的数据，exclusive：只有本cache line有的数据，Shared：包含与别的cache 一样的数据，没有修改的数据，invalid:指cache line空的，或者dropped，意味着它没有任何有效数据。 对于多核CPU来着，cache 的状态变化会在这四个状态间切换，比如一个核心独占的cache，如果别的核心也需要的话，状态就会变成共享的。 另外也有一些变种的协议，加上一些别的状态，比如修改过的cache并不马上写回到下一个level中，而是同样可以共享。\n对性能的影响 use std::{hint::black_box, sync::atomic::AtomicU32, sync::atomic::Ordering::*, time::Instant}; static A: AtomicU32 = AtomicU32::new(0); fn main() { black_box(\u0026A); std::thread::spawn(|| loop { black_box(A.store(1, Relaxed)); }); let start = Instant::now(); for _ in 0..1_000_000_000 { black_box(A.load(Relaxed)); } println!(\"time is:{:?}\", start.elapsed()); } 这段代码，如果store改成load，那么cache line的同步的开销几乎可以不计，对多线程的load没有什么影响，但是如果是store，会有很大同步的开销的，在我的老笔记本上，这个执行时间从11秒变到了40秒（不是，我的笔记本也太差了，书中写的是现在的新x86CPU从200ms变成600ms）。\n原因是store的话，需要独占整个cache line，并且要写回到下一层，再被其它线程去load。如果把指令改成cmp \u0026 echg，也是一样的，因为无论cmp失败与否，它都需要独占cache line。\n如果是多个变量在同一条cache line上，对于这些变量的操作也会受到cache一致性的影响，性能会有所下降，最好是把不同的变量分到不同的cache line上。\nstatic A: [AtomicU32;3] = [AtomicU32::new(0),AtomicU32::new(0),AtomicU32::new(0)]; fn main() { black_box(\u0026A); std::thread::spawn(|| loop { black_box(A[0].store(1, Relaxed)); black_box(A[2].store(1, Relaxed)); }); let start = Instant::now(); for _ in 0..1_000_000_000 { black_box(A[1].load(Relaxed)); } println!(\"time is:{:?}\", start.elapsed()); } 输出结果\ntime is: 38.1021 而改进方法是，对变量填充padding，让它占满整个cache line，这样就会互不影响了。\n#[repr(align(64))] struct Aligned(AtomicU32); static A: [Aligned;3] = [Aligned(AtomicU32::new(0)),Aligned(AtomicU32::new(0)),Aligned(AtomicU32::new(0))]; fn main() { black_box(\u0026A); std::thread::spawn(|| loop { black_box(A[0].0.store(1, Relaxed)); black_box(A[2].0.store(1, Relaxed)); }); let start = Instant::now(); for _ in 0..1_000_000_000 { black_box(A[1].0.load(Relaxed)); } println!(\"time is:{:?}\", start.elapsed()); } 输出为time is 11.12121，可见影响是非常大的。\nReordering 指令重排不仅会发生在编译器生成的时候，而且也会发生指令乱序执行的情况。在现代CPU中，存在一些优化性能的机制，会导致指令的乱序执行。\nstore buffer CPU对cache的操作可能先存入store buffer中，然后先去执行别的指令，对于别的线程来说，可能要等store buffer写入了cache后，再通过MESI同步过去。\ninvaliation queue 同样对于缓存的失效也并不是马上落到cache中，而是先放入一个invaliation queue中，之后再进行失效操作，如果别的核心需要等待这个操作才能执行，那么会在queue写入到cache后才会执行。\npipeline 现代CPU的流水线是高度并行执行指令的，在CPU中会分析指令间的依赖关系，然后同时发射，但是对于编译生成的指令来着，却是乱序的。\n对于store buffer导致的指令重排，可以使用内存屏障来保证写操作一定在读操作之前。\nMemory ordering 在现代语言中，如果指定了内存模型的话，那么编译器会生成正确的指令，不会生成打破内存模型的重排指令。但是比如non-atomic操作与relaxed模型，重排是可以接收的，换句话说，重排与否与操作和内存模型有关系。 对于内存屏障来说，所有的acquire之后的操作都不能重排在acquire之前，而release之后的操作都不能重排到release之前。 对于GPU来说，复杂的缓存设计与内存设计可能会导致core1的操作与core2的操作在core3看来并不是按core1 core2约定的顺序执行的。而x86与arm，一个核心的操作对于其它核心是可见的，即保证了在其它核心看来也是同一样的顺序，这样数据不同步的问题在这两个架构来看，是能退化成指令重排的问题。arm用的是weakly ordering，可以允许可能的重排，而x86是strong ordering，对于指令重排有严格的限制。\n在x86上，保证了store-store的连续性，即store a与store一定是按写下的顺序写下的，同理load a与load b也是一样。唯一允许的重排是store after load，这指的是core1有load a 后面跟了一个store b操作，而core2可以通过store buffer forwarding等优化技术来先load b，这样观察顺序看来就是core1: load a-\u003estore b-\u003eload b-\u003estore-a,core2: load-a load-b store a store b，这样的顺序，而实际执行顺序是没有变的。\n在x86上，可以说得到了免费的acquire-release语义的保障，可以说与relaxed模型一样的开销，因为non-atomic操作与atomic操作生成的汇编是一样的，除了SeqCst，要保证全局一致性需要把store改成xexchg，因为普通的store会可能重排。 可以说，在性能上只有store在不同内存序下有性能差异，而其它的load等操作在seqcst和relaxed操作下是没有差异的。\n在arm上，因为弱内存序，所有的指令都有可能发生重排。所以加上强内存序后，会生成强内存序的指令，可以保证一致性。而且acq-rel与seq-cst生成的代码是一样的。\n对于fence来说，在x86上，只有SeqCst下，才会生成mfence的指令，而在arm上都会生成dms的指令用于等待load store完成，并且防止指令重排。\nOperating system interface 在不同系统上，Rust基本上都通过libc去做syscall来完成与系统内核的交互： * linux上，syscall abi是稳定的，也可以通过汇编下的syscall来实现syscall，虽然这样更快，但是丧失了一些方便性。 * macos上，syscall abi不是稳定的，所以一般都是使用libc提供的posix接口来实现syscall。 * 在windows上也有kernel32.dll来提供syscall。\nposix posix标准下，有pthread作为线程库与同步原语: * pthread_mutex_t: 创建mutex为pthread_mutex_init,退出pthread_mutex_destroy，可以在init在时候传入attr参数来指定一些属性，一个比较重要的属性是重入性，默认情况下PTHREAD_MUTEX_DEFAULT 是不能重入，可以配置成PTHREAD_MTUEX_ERRCHECK用于报错，配置成PTHEAD_MUTEX_NORMAL会死锁，配置成PTHREAD_MUTEX_RECURSIVE 后mutex即是可重入的。同样还有pthread_mutex_timelock用于有限时间的加锁 * pthread_rwlock_t：与mutex类似也有同样的函数用于创建，退出，同样的默认初始化是用一个宏PTHREAD_RWLOCK_INITALIZER来初始化，write-lock是不可重入的，会导致死锁。read-loack是可重入的，但是在pthread的实现中，读者的等级与高于写者的，读者一直拿着，写者需要一直等待所有的读者都释放锁。 * pthread_cont_t: 同样与mutex类似，都是有一系列函数用于创建，销毁，值得一说的是限时的cond是可以配置成使用instance时间还是wall clock。 * 还有pthread_barrier_it，pthread_sping_lock_t 和once类型pthread_once_t\n在rust中包装pthread 包装的时候，因为pthread都是用的地址，与指针强相关，甚至还会有自引用地址，而rust中语义为move，要做到两者的兼容，一个做法是用box包一层:\npub struct Mutex{ m : Box\u003cUnsafeCell\u003clibc::pthread_mutex_t\u003e\u003e; } 在1.62之前的mutex是这么实现的。这样的实现也会带来一些问题，比如访问的开销，无法把mutex的一些函数变成const fn。一个更大的问题是，MutexGarud是可以使用std::mem::forget来提前释放掉的，在一个scope里，如果一个lock先lock，然后mutexguard释放掉了，然后lock在没有Unlock的情况下去释放，这种情况是ub。 ps1（虽然文中没有提到后面是版本是怎么实现的，但是我觉得在有futex的情况下，应该都是用的futex来实现的） ps2:看了一下代码，实现const的方式是用OnceBox包了一层，drop的问题，如果已经lock了要去drop的时候，同样把这个mutex给leak掉。 https://github.com/rust-lang/rust/blob/master/library/std/src/sys/sync/mutex/pthread.rs\nlinux 在Linux上，mutex是用linux提供的一个syscall来实现的，叫SYS_FUTEX。其中包含两个操作，一个是FUTEX_WAIT，一个是FUTEX_WAKE，wait会让线程睡眠，而wake会唤醒。 用futex实现mutex的核心机制是在用户态使用一个atomic变量来表示是否锁住了，当线程A把变量改成1代表持有锁，线程B再去拿的时候，内核会让线程B进入睡眠，然后放入等待队列中，等待唤醒。但是如果可以拿到锁的话，那么就不用进入内核态，大大减少了开销。 rust上的实现如此：https://github.com/rust-lang/rust/blob/master/library/std/src/sys/sync/mutex/futex.rs。\nfutex operations 一般fuex函数有两个参数，一个是watch的atomic i32变量，一个是操作。 一些操作如链接：https://www.man7.org/linux/man-pages/man2/futex.2.html 一些值得一提的是requeue,当多个线程排队时，第一个线程拿到了变量后，将其它线程重新入队等待另一个变量的值。 futex_wake(wait)_bitset，通过mask来指定wait wake，不会引起惊群。另外就是用于实现rwlock的时候，可以用不同的bit来代表reader writer。 FUTEX_PRIVATE_FLAG，代表所有对同一个atomic操作的线程都是同一个进程，不会跨进程操作，在调用的时候，所有的调用都得带上这个flag。 优化级相关：当进程优先级高的进程，等待进程优先级低的进程的时候，这叫优先级反转，而futex的做法是，当低优先级线程持有锁时，它会临时继承等待该锁的最高优先级线程的优先级。 对于内核来说，需要futex将atomic变量设置为线程ID,用低30位。用高位来代表解锁与否。\nmacos mac用的是pthread实现。但是速度比其它unix平台慢跑，原因是它用的是公平锁，先来先得的机制的。后面10.12才推出了非公平锁。\nWindows windows上的mutex叫critical setion，是可重入的。这个比较重。轻量级的有类似于linux的futex叫WaitOnAdress。还有SRW lock。\n其余的同步原语 semaphore semaphore即OS书中学到的PV操作的同步原语，wait操作会把couter减1，而signal操作会会把couter加1，如果wait遇到counter为0的时候，就会被block住，需要等到signal把counter+1才能唤醒另一个线程。实现上，一个实现是，用一个mutex来保护counter，一个convar来做wait和signal的操作，实现对线程的wait和wake操作。在linux上可以用futex来实现，这样只要用到一个atomic的u32即可实现。\nrcu rcu是一个可以用于大量的数据，多读少写的场景写的无锁数据结构，核心思想是在对一个node做修改的时候，copy一个node出去，让它先修改，其它读者会读到老的数据，然后修改完之后，把node再更新掉： 其中最大的问题在于最后一步，如果还有读者在引用老数据的话，需要等所有的读者都不在引用老数据才能释放掉老数据。 linux rcu C++ rcu\n无锁链表 如图所示，这三步操作都可以atomic的完成。值得注意的是，可能会有多个写者来更新插入，要保证只有一个能更新成功。删除一个节点的时候，也有相同的问题，即什么时候才能释放这个节点。可以使用hazerd pointer或者引用计数等技术能实现。 https://lwn.net/Articles/610972/\nQueue-Based Locks 核心思想是，只维护一个atomic pointer，然后指向一个队列，其中指针中没有使用的位，可以用来表示锁的状态。windows里面的slim read write lock就是这么实现的。 ## Parking Lot–Based Locks parking lot 锁是对queue based lock的优化，可以把mutex优化的尽量小，即mutex只用来表示是否有锁，是否有队列，然后另外一个全局变量hashmap来表示，以adress为key，以queue为value。\nrust中有一个parking_lot就是如此实现的。当然它还有很多优化，优化性能，否则会对hashmpa抢占很严重。\nSequence Lock Sequence lock的思路是在结构中加上一个counter,当写者进行写的时候，把couter变成奇数，写完之后，再把counter变成偶数，所有的读者都可以随便读数据，但是需要比较前后的couter的数值，如果都是偶数且没有变化，则是有效，否则要重试。\nSeqLock\n","wordCount":"404","inLanguage":"en","image":"https://linxy.dev/images/papermod-cover.png","datePublished":"2025-04-10T17:25:14+08:00","dateModified":"2025-04-10T17:25:14+08:00","author":{"@type":"Person","name":"linxy"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://linxy.dev/posts/rust-atomic/"},"publisher":{"@type":"Organization","name":"linxy's blog","logo":{"@type":"ImageObject","url":"https://linxy.dev/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://linxy.dev/ accesskey=h title="linxy's blog (Alt + H)">linxy's blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://linxy.dev/archives title=Archive><span>Archive</span></a></li><li><a href=https://linxy.dev/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://linxy.dev/>Home</a>&nbsp;»&nbsp;<a href=https://linxy.dev/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Rust Atomic 笔记</h1><div class=post-meta><span title='2025-04-10 17:25:14 +0800 +0800'>April 10, 2025</span>&nbsp;·&nbsp;<span>2 min</span>&nbsp;·&nbsp;<span>linxy</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#basic-of-rust-concurrency aria-label="basic of rust concurrency">basic of rust concurrency</a></li><li><a href=#atomic-and-memory-order aria-label="Atomic and Memory order">Atomic and Memory order</a><ul><li><a href=#relax aria-label=Relax>Relax</a></li><li><a href=#relaase-and-acquire aria-label="Relaase and Acquire">Relaase and Acquire</a></li><li><a href=#consume aria-label=consume>consume</a></li><li><a href=#seqcst aria-label=SeqCst>SeqCst</a></li></ul></li><li><a href=#understanding-the-processor aria-label="Understanding the processor">Understanding the processor</a><ul><li><a href=#load-linked-and-store-conditinal-instructions aria-label="load-linked and store-conditinal instructions">load-linked and store-conditinal instructions</a></li><li><a href=#cache aria-label=cache>cache</a></li><li><a href=#%e5%af%b9%e6%80%a7%e8%83%bd%e7%9a%84%e5%bd%b1%e5%93%8d aria-label=对性能的影响>对性能的影响</a></li><li><a href=#reordering aria-label=Reordering>Reordering</a><ul><li><a href=#store-buffer aria-label="store buffer">store buffer</a></li><li><a href=#invaliation-queue aria-label="invaliation queue">invaliation queue</a></li><li><a href=#pipeline aria-label=pipeline>pipeline</a></li></ul></li><li><a href=#memory-ordering aria-label="Memory ordering">Memory ordering</a></li></ul></li><li><a href=#operating-system-interface aria-label="Operating system interface">Operating system interface</a><ul><li><a href=#posix aria-label=posix>posix</a><ul><li><a href=#%e5%9c%a8rust%e4%b8%ad%e5%8c%85%e8%a3%85pthread aria-label=在rust中包装pthread>在rust中包装pthread</a></li></ul></li><li><a href=#linux aria-label=linux>linux</a><ul><li><a href=#futex-operations aria-label="futex operations">futex operations</a></li></ul></li><li><a href=#macos aria-label=macos>macos</a></li><li><a href=#windows aria-label=Windows>Windows</a></li></ul></li><li><a href=#%e5%85%b6%e4%bd%99%e7%9a%84%e5%90%8c%e6%ad%a5%e5%8e%9f%e8%af%ad aria-label=其余的同步原语>其余的同步原语</a><ul><li><a href=#semaphore aria-label=semaphore>semaphore</a></li><li><a href=#rcu aria-label=rcu>rcu</a></li><li><a href=#%e6%97%a0%e9%94%81%e9%93%be%e8%a1%a8 aria-label=无锁链表>无锁链表</a></li><li><a href=#queue-based-locks aria-label="Queue-Based Locks">Queue-Based Locks</a></li><li><a href=#sequence-lock aria-label="Sequence Lock">Sequence Lock</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=basic-of-rust-concurrency>basic of rust concurrency<a hidden class=anchor aria-hidden=true href=#basic-of-rust-concurrency>#</a></h1><p>内部可变性是指可以通一个不可变引用来实现对内部数据的修改。标准库中有<code>Cell&lt;T></code>，Cell相当于持有这个Obj，要做修改只能先把T move出来再把T塞回去。<code>RefCell&lt;T></code>不但持有这个obj，还会维护一个引用计数，如果在运行时有多个Mut借用时，会panic。<br><code>RwLock</code>是多线程版本的<code>RefCell</code>，但是多个可变借用时，或者说多个写时，会block住试图拿这个可变借用的线程，让它进入sleep。而<code>Mutex</code>不像Rwlock可以实现多个可读借用，mutex是彻底的独占的，其它线程都必须等待锁的释放。<br><code>UnSafeCell</code>是实现内部可变性的关键类型，它只有get函数可以得到一个底层类型的raw pointer,<code>UnsafeCell</code>没有任何保证安全性的限制，需要用户自己来进行安全性的保证。一般不会直接用unsafe cell，都是包装成另一个类型来限制使用，比如实现成cell或者mutex。<br><code>Send</code>trait意味着这个类型的所有权可以在线程之间转移，<code>Sync</code>trait意味着这个类型可以在线程之间共享。<br>一个struct如果所有的类型都是send和sync，那它本身也是send和sync的，如果要实现非send和sync的话，可以用phontomdata 标记类型。PhantomData用于标记Struct非sync，毕竟这是个zero sized type。<br>给一些非auto trait实现send和sync是unsafe的，因为取决于其中类型的具体实现，所以安全性需要自己来保证。<br>rust的mutex，实现了一个其它线程如果持有了mutex，但是panic了，这个mutex就是poison的机制：<a href=https://doc.rust-lang.org/std/sync/struct.Mutex.html#poisoning>rust mutex doc</a>。
mutex一些值得注意的点:</p><ol><li><p>if let的scope。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>if</span><span class=w> </span><span class=kd>let</span><span class=w> </span><span class=nb>Some</span><span class=p>(</span><span class=n>item</span><span class=p>)</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>list</span><span class=p>.</span><span class=n>lock</span><span class=p>().</span><span class=n>unwrap</span><span class=p>().</span><span class=n>pop</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=c1>//会lock到这个if结束
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>process_item</span><span class=p>(</span><span class=n>item</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>if</span><span class=w> </span><span class=n>list</span><span class=p>.</span><span class=n>lock</span><span class=p>().</span><span class=n>unwrap</span><span class=p>().</span><span class=n>pop</span><span class=p>()</span><span class=w> </span><span class=o>==</span><span class=w> </span><span class=nb>Some</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=c1>//在进入body前，MutxGuard就已经drop掉了。
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>        </span><span class=n>do_something</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div></li><li><p>rust 2024做出的一个if let的小修改，即if let的表达式生命周期不会延长到else body中去：<a href=https://doc.rust-lang.org/edition-guide/rust-2024/temporary-if-let-scope.html>rust 2024 doc</a></p></li></ol><p>大多数的读写锁的实现都会block新的读者出现，当写者等待时，因为可能会多个读者共享导致写者一直要等待，这是读写锁中一个经典的饥饿问题。
## parking and condition variables
当一个线程在等待别的线程的通知的时候，这种叫thread parking，parking的时候，线程会进入睡眠，唤醒可以用unpark。
在实现上，unpark有一个很重要的特性是，有一个信号保留机制，即unpark在park之前执行了，这个park也不会让线程进入睡眠，因为消费者需要对生产者的每一个unpark都有响应，否则会有丢数据的风险。
但是unpark并不能叠加，所以unpark两次后，再Park两次还是会线程进入睡眠。</p><p>条件变量一般是与mutex结合使用，传入同一个mutex，一个线程wait，一个线程notify。如果两个线程在操作同一个条件变量但是不同的mutex，会引起panic.</p><h1 id=atomic-and-memory-order>Atomic and Memory order<a hidden class=anchor aria-hidden=true href=#atomic-and-memory-order>#</a></h1><p>原子类型可以在多线程间安全的访问和修改，但是依赖于Memory Ordering。比如最简单的order,Ralex,Relax只能保证单个变量的一致性，而多个变量间顺序无法保证。
atomic i32的溢出是回环的，不像普通的i32，溢出是会panic的。
为什么需要memory order?CPU会为了优化而把程序中的指令进行重排，写的是什么顺序，执行起来可能是别的顺序。
Happens before即保证A发生在B之前，但是在多线程中却是不一定的，使用锁可以保证，或者更严格的memory ordering。</p><h2 id=relax>Relax<a hidden class=anchor aria-hidden=true href=#relax>#</a></h2><p>Relaxed Ordering保证了单个atomic变量的总修改顺序.</p><h2 id=relaase-and-acquire>Relaase and Acquire<a hidden class=anchor aria-hidden=true href=#relaase-and-acquire>#</a></h2><p>Release与Acquire是成对使用，release给store，acquire给load。acquire-load可以观测到所有的release-store的操作，可以保证所有的store都会发生在load之前。同时，还有一个两者的结合体，即AcqRel。</p><h2 id=consume>consume<a hidden class=anchor aria-hidden=true href=#consume>#</a></h2><p>只能说，load发生的时候，取决于这个值的读取操作，只能说store肯定发生于相关表达式求值这前，而非相关的肯定不会。但是实际上所有的CPU都是实现为relax，而编译器根本不支持这个操作。不会保证全局顺序的一致性。</p><h2 id=seqcst>SeqCst<a hidden class=anchor aria-hidden=true href=#seqcst>#</a></h2><p>SeqCst保证了所有的acquire ordering与release ordering，也保证了全局操作顺序的一致性。如果在乎性能可以使用 seqcst fence与relaxed ordering来代替。</p><p>实际上release store可以分解成fence与relaxed ordering,因为fence会导致同步：
<img loading=lazy src=/images/b597744cfb3b703b7446bca16de1b7987e8644b1.png></p><p>所有的store在release fence后面 会被acquire fence之前被观测到，即同步</p><h1 id=understanding-the-processor>Understanding the processor<a hidden class=anchor aria-hidden=true href=#understanding-the-processor>#</a></h1><p>在x86和arm下，最低要求的Relaxed的load和store，与普通变量的读取与写入是一样的。（我觉得主要原因是x86是TSO，远大于Relaxed的同步要求，而arm这是默认最低水平的同步要求。）
但是如果是Read-Modify-Write这样的顺序的话，比如<code>*x+=1</code>，这样的语句，对于x86来说，只有一条mov，这样是原子的，但是对于arm来说，这是三条指令，这意味着它并不是原子的了。
普通的add并不是原子的，因为在cpu看到会拆成好多条微指令，所以并不是原子的，如果要实现原子性的add或者其它操作，需要用到x86下的lock 前缀。
在x86下，add,sub,and not or xor都支持lock前缀，当它们加上了lock前缀之后，会block住其它核心 ，之后会将结果同步给其它核心，以完成同步。
只有add有xadd指针，x意味首exchange；对于bit，可以用bts，btr，btc指令来实现，这些指令也可以加lock。
而compare and exchange有<code>cmpxchg</code> 指令，可以实现比较然后交换。</p><h2 id=load-linked-and-store-conditinal-instructions>load-linked and store-conditinal instructions<a hidden class=anchor aria-hidden=true href=#load-linked-and-store-conditinal-instructions>#</a></h2><p>对于RISC架构来说，LL/SC loop是最接近cmp and exchange语义的。其中包含了两个基本指令，一个load，一个store-conditional。与普通的load store不一样的是，如果在store的时候，有其它线程在load-link指令后写入内存，store会拒绝写入。
用这两个指令，可以实现读取，修改，写入，如果中间因为别的线程有修改写入失败了，则重试即可。
在x86用fetch等指令，可以生成与compare and exchange相同的指令，但是在arm上并不一定，这种优化实际上很难做，因为ll store中间能插的指令过少</p><h2 id=cache>cache<a hidden class=anchor aria-hidden=true href=#cache>#</a></h2><p>MESI的四个状态，modified：包含了本cach line修改了但是没有写回主存的数据，exclusive：只有本cache line有的数据，Shared：包含与别的cache 一样的数据，没有修改的数据，invalid:指cache line空的，或者dropped，意味着它没有任何有效数据。
对于多核CPU来着，cache 的状态变化会在这四个状态间切换，比如一个核心独占的cache，如果别的核心也需要的话，状态就会变成共享的。
另外也有一些变种的协议，加上一些别的状态，比如修改过的cache并不马上写回到下一个level中，而是同样可以共享。</p><h2 id=对性能的影响>对性能的影响<a hidden class=anchor aria-hidden=true href=#对性能的影响>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>use</span><span class=w> </span><span class=n>std</span>::<span class=p>{</span><span class=n>hint</span>::<span class=n>black_box</span><span class=p>,</span><span class=w> </span><span class=n>sync</span>::<span class=n>atomic</span>::<span class=n>AtomicU32</span><span class=p>,</span><span class=w> </span><span class=n>sync</span>::<span class=n>atomic</span>::<span class=n>Ordering</span>::<span class=o>*</span><span class=p>,</span><span class=w> </span><span class=n>time</span>::<span class=n>Instant</span><span class=p>};</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>static</span><span class=w> </span><span class=n>A</span>: <span class=nc>AtomicU32</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>AtomicU32</span>::<span class=n>new</span><span class=p>(</span><span class=mi>0</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>fn</span> <span class=nf>main</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>black_box</span><span class=p>(</span><span class=o>&amp;</span><span class=n>A</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>std</span>::<span class=n>thread</span>::<span class=n>spawn</span><span class=p>(</span><span class=o>||</span><span class=w> </span><span class=k>loop</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>black_box</span><span class=p>(</span><span class=n>A</span><span class=p>.</span><span class=n>store</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=w> </span><span class=n>Relaxed</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>});</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kd>let</span><span class=w> </span><span class=n>start</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>Instant</span>::<span class=n>now</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>for</span><span class=w> </span><span class=n>_</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=mi>0</span><span class=o>..</span><span class=mi>1_000_000_000</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>black_box</span><span class=p>(</span><span class=n>A</span><span class=p>.</span><span class=n>load</span><span class=p>(</span><span class=n>Relaxed</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=fm>println!</span><span class=p>(</span><span class=s>&#34;time is:</span><span class=si>{:?}</span><span class=s>&#34;</span><span class=p>,</span><span class=w> </span><span class=n>start</span><span class=p>.</span><span class=n>elapsed</span><span class=p>());</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>这段代码，如果store改成load，那么cache line的同步的开销几乎可以不计，对多线程的load没有什么影响，但是如果是store，会有很大同步的开销的，在我的老笔记本上，这个执行时间从11秒变到了40秒（不是，我的笔记本也太差了，书中写的是现在的新x86CPU从200ms变成600ms）。</p><p>原因是store的话，需要独占整个cache line，并且要写回到下一层，再被其它线程去load。如果把指令改成cmp & echg，也是一样的，因为无论cmp失败与否，它都需要独占cache line。</p><p>如果是多个变量在同一条cache line上，对于这些变量的操作也会受到cache一致性的影响，性能会有所下降，最好是把不同的变量分到不同的cache line上。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>static</span><span class=w> </span><span class=n>A</span>: <span class=p>[</span><span class=n>AtomicU32</span><span class=p>;</span><span class=mi>3</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>[</span><span class=n>AtomicU32</span>::<span class=n>new</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span><span class=n>AtomicU32</span>::<span class=n>new</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span><span class=n>AtomicU32</span>::<span class=n>new</span><span class=p>(</span><span class=mi>0</span><span class=p>)];</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>fn</span> <span class=nf>main</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>black_box</span><span class=p>(</span><span class=o>&amp;</span><span class=n>A</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>std</span>::<span class=n>thread</span>::<span class=n>spawn</span><span class=p>(</span><span class=o>||</span><span class=w> </span><span class=k>loop</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>black_box</span><span class=p>(</span><span class=n>A</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>store</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=w> </span><span class=n>Relaxed</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>black_box</span><span class=p>(</span><span class=n>A</span><span class=p>[</span><span class=mi>2</span><span class=p>].</span><span class=n>store</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=w> </span><span class=n>Relaxed</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>});</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kd>let</span><span class=w> </span><span class=n>start</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>Instant</span>::<span class=n>now</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>for</span><span class=w> </span><span class=n>_</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=mi>0</span><span class=o>..</span><span class=mi>1_000_000_000</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>black_box</span><span class=p>(</span><span class=n>A</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>load</span><span class=p>(</span><span class=n>Relaxed</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=fm>println!</span><span class=p>(</span><span class=s>&#34;time is:</span><span class=si>{:?}</span><span class=s>&#34;</span><span class=p>,</span><span class=w> </span><span class=n>start</span><span class=p>.</span><span class=n>elapsed</span><span class=p>());</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>输出结果</p><pre><code>time is: 38.1021
</code></pre><p>而改进方法是，对变量填充padding，让它占满整个cache line，这样就会互不影响了。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=cp>#[repr(align(64))]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>struct</span> <span class=nc>Aligned</span><span class=p>(</span><span class=n>AtomicU32</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>static</span><span class=w> </span><span class=n>A</span>: <span class=p>[</span><span class=n>Aligned</span><span class=p>;</span><span class=mi>3</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>[</span><span class=n>Aligned</span><span class=p>(</span><span class=n>AtomicU32</span>::<span class=n>new</span><span class=p>(</span><span class=mi>0</span><span class=p>)),</span><span class=n>Aligned</span><span class=p>(</span><span class=n>AtomicU32</span>::<span class=n>new</span><span class=p>(</span><span class=mi>0</span><span class=p>)),</span><span class=n>Aligned</span><span class=p>(</span><span class=n>AtomicU32</span>::<span class=n>new</span><span class=p>(</span><span class=mi>0</span><span class=p>))];</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>fn</span> <span class=nf>main</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>black_box</span><span class=p>(</span><span class=o>&amp;</span><span class=n>A</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>std</span>::<span class=n>thread</span>::<span class=n>spawn</span><span class=p>(</span><span class=o>||</span><span class=w> </span><span class=k>loop</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>black_box</span><span class=p>(</span><span class=n>A</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=mf>0.</span><span class=n>store</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=w> </span><span class=n>Relaxed</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>black_box</span><span class=p>(</span><span class=n>A</span><span class=p>[</span><span class=mi>2</span><span class=p>].</span><span class=mf>0.</span><span class=n>store</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=w> </span><span class=n>Relaxed</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>});</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=kd>let</span><span class=w> </span><span class=n>start</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>Instant</span>::<span class=n>now</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>for</span><span class=w> </span><span class=n>_</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=mi>0</span><span class=o>..</span><span class=mi>1_000_000_000</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>black_box</span><span class=p>(</span><span class=n>A</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=mf>0.</span><span class=n>load</span><span class=p>(</span><span class=n>Relaxed</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=fm>println!</span><span class=p>(</span><span class=s>&#34;time is:</span><span class=si>{:?}</span><span class=s>&#34;</span><span class=p>,</span><span class=w> </span><span class=n>start</span><span class=p>.</span><span class=n>elapsed</span><span class=p>());</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>输出为<code>time is 11.12121</code>，可见影响是非常大的。</p><h2 id=reordering>Reordering<a hidden class=anchor aria-hidden=true href=#reordering>#</a></h2><p>指令重排不仅会发生在编译器生成的时候，而且也会发生指令乱序执行的情况。在现代CPU中，存在一些优化性能的机制，会导致指令的乱序执行。</p><h3 id=store-buffer>store buffer<a hidden class=anchor aria-hidden=true href=#store-buffer>#</a></h3><p>CPU对cache的操作可能先存入store buffer中，然后先去执行别的指令，对于别的线程来说，可能要等store buffer写入了cache后，再通过MESI同步过去。</p><h3 id=invaliation-queue>invaliation queue<a hidden class=anchor aria-hidden=true href=#invaliation-queue>#</a></h3><p>同样对于缓存的失效也并不是马上落到cache中，而是先放入一个invaliation queue中，之后再进行失效操作，如果别的核心需要等待这个操作才能执行，那么会在queue写入到cache后才会执行。</p><h3 id=pipeline>pipeline<a hidden class=anchor aria-hidden=true href=#pipeline>#</a></h3><p>现代CPU的流水线是高度并行执行指令的，在CPU中会分析指令间的依赖关系，然后同时发射，但是对于编译生成的指令来着，却是乱序的。</p><p>对于store buffer导致的指令重排，可以使用内存屏障来保证写操作一定在读操作之前。</p><h2 id=memory-ordering>Memory ordering<a hidden class=anchor aria-hidden=true href=#memory-ordering>#</a></h2><p>在现代语言中，如果指定了内存模型的话，那么编译器会生成正确的指令，不会生成打破内存模型的重排指令。但是比如non-atomic操作与relaxed模型，重排是可以接收的，换句话说，重排与否与操作和内存模型有关系。
对于内存屏障来说，所有的acquire之后的操作都不能重排在acquire之前，而release之后的操作都不能重排到release之前。
对于GPU来说，复杂的缓存设计与内存设计可能会导致core1的操作与core2的操作在core3看来并不是按core1 core2约定的顺序执行的。而x86与arm，一个核心的操作对于其它核心是可见的，即保证了在其它核心看来也是同一样的顺序，这样数据不同步的问题在这两个架构来看，是能退化成指令重排的问题。arm用的是weakly ordering，可以允许可能的重排，而x86是strong ordering，对于指令重排有严格的限制。</p><p>在x86上，保证了store-store的连续性，即store a与store一定是按写下的顺序写下的，同理load a与load b也是一样。唯一允许的重排是store after load，这指的是core1有load a 后面跟了一个store b操作，而core2可以通过store buffer forwarding等优化技术来先load b，这样观察顺序看来就是core1: load a->store b->load b->store-a,core2: load-a load-b store a store b，这样的顺序，而实际执行顺序是没有变的。</p><p>在x86上，可以说得到了免费的acquire-release语义的保障，可以说与relaxed模型一样的开销，因为non-atomic操作与atomic操作生成的汇编是一样的，除了SeqCst，要保证全局一致性需要把store改成xexchg，因为普通的store会可能重排。
可以说，在性能上只有store在不同内存序下有性能差异，而其它的load等操作在seqcst和relaxed操作下是没有差异的。</p><p>在arm上，因为弱内存序，所有的指令都有可能发生重排。所以加上强内存序后，会生成强内存序的指令，可以保证一致性。而且acq-rel与seq-cst生成的代码是一样的。</p><p>对于fence来说，在x86上，只有SeqCst下，才会生成mfence的指令，而在arm上都会生成dms的指令用于等待load store完成，并且防止指令重排。</p><p><img loading=lazy src=/images/5c1705d6c79f7b3ffda36f2fac0285ec0374cd08.png></p><h1 id=operating-system-interface>Operating system interface<a hidden class=anchor aria-hidden=true href=#operating-system-interface>#</a></h1><p>在不同系统上，Rust基本上都通过libc去做syscall来完成与系统内核的交互：
* linux上，syscall abi是稳定的，也可以通过汇编下的syscall来实现syscall，虽然这样更快，但是丧失了一些方便性。
* macos上，syscall abi不是稳定的，所以一般都是使用libc提供的posix接口来实现syscall。
* 在windows上也有<code>kernel32.dll</code>来提供syscall。</p><h2 id=posix>posix<a hidden class=anchor aria-hidden=true href=#posix>#</a></h2><p>posix标准下，有pthread作为线程库与同步原语:
* <code>pthread_mutex_t</code>: 创建mutex为<code>pthread_mutex_init</code>,退出<code>pthread_mutex_destroy</code>，可以在init在时候传入attr参数来指定一些属性，一个比较重要的属性是重入性，默认情况下<code>PTHREAD_MUTEX_DEFAULT</code> 是不能重入，可以配置成<code>PTHREAD_MTUEX_ERRCHECK</code>用于报错，配置成<code>PTHEAD_MUTEX_NORMAL</code>会死锁，配置成<code>PTHREAD_MUTEX_RECURSIVE</code> 后mutex即是可重入的。同样还有<code>pthread_mutex_timelock</code>用于有限时间的加锁
* <code>pthread_rwlock_t</code>：与mutex类似也有同样的函数用于创建，退出，同样的默认初始化是用一个宏<code>PTHREAD_RWLOCK_INITALIZER</code>来初始化，write-lock是不可重入的，会导致死锁。read-loack是可重入的，但是在pthread的实现中，读者的等级与高于写者的，读者一直拿着，写者需要一直等待所有的读者都释放锁。
* <code>pthread_cont_t</code>: 同样与mutex类似，都是有一系列函数用于创建，销毁，值得一说的是限时的cond是可以配置成使用instance时间还是wall clock。
* 还有<code>pthread_barrier_it</code>，<code>pthread_sping_lock_t</code> 和once类型<code>pthread_once_t</code></p><h3 id=在rust中包装pthread>在rust中包装pthread<a hidden class=anchor aria-hidden=true href=#在rust中包装pthread>#</a></h3><p>包装的时候，因为pthread都是用的地址，与指针强相关，甚至还会有自引用地址，而rust中语义为move，要做到两者的兼容，一个做法是用box包一层:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>pub</span><span class=w> </span><span class=k>struct</span> <span class=nc>Mutex</span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>m</span><span class=w> </span>: <span class=nb>Box</span><span class=o>&lt;</span><span class=n>UnsafeCell</span><span class=o>&lt;</span><span class=n>libc</span>::<span class=n>pthread_mutex_t</span><span class=o>&gt;&gt;</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>在1.62之前的mutex是这么实现的。这样的实现也会带来一些问题，比如访问的开销，无法把mutex的一些函数变成const fn。一个更大的问题是，<code>MutexGarud</code>是可以使用<code>std::mem::forget</code>来提前释放掉的，在一个scope里，如果一个lock先lock，然后mutexguard释放掉了，然后lock在没有Unlock的情况下去释放，这种情况是ub。
ps1（虽然文中没有提到后面是版本是怎么实现的，但是我觉得在有futex的情况下，应该都是用的futex来实现的）
ps2:看了一下代码，实现const的方式是用OnceBox包了一层，drop的问题，如果已经lock了要去drop的时候，同样把这个mutex给leak掉。
<a href=https://github.com/rust-lang/rust/blob/master/library/std/src/sys/sync/mutex/pthread.rs>https://github.com/rust-lang/rust/blob/master/library/std/src/sys/sync/mutex/pthread.rs</a></p><h2 id=linux>linux<a hidden class=anchor aria-hidden=true href=#linux>#</a></h2><p>在Linux上，mutex是用linux提供的一个syscall来实现的，叫SYS_FUTEX。其中包含两个操作，一个是FUTEX_WAIT，一个是FUTEX_WAKE，wait会让线程睡眠，而wake会唤醒。
用futex实现mutex的核心机制是在用户态使用一个atomic变量来表示是否锁住了，当线程A把变量改成1代表持有锁，线程B再去拿的时候，内核会让线程B进入睡眠，然后放入等待队列中，等待唤醒。但是如果可以拿到锁的话，那么就不用进入内核态，大大减少了开销。
rust上的实现如此：https://github.com/rust-lang/rust/blob/master/library/std/src/sys/sync/mutex/futex.rs。</p><h3 id=futex-operations>futex operations<a hidden class=anchor aria-hidden=true href=#futex-operations>#</a></h3><p>一般fuex函数有两个参数，一个是watch的atomic i32变量，一个是操作。
一些操作如链接：https://www.man7.org/linux/man-pages/man2/futex.2.html
一些值得一提的是requeue,当多个线程排队时，第一个线程拿到了变量后，将其它线程重新入队等待另一个变量的值。
<code>futex_wake(wait)_bitset</code>，通过mask来指定wait wake，不会引起惊群。另外就是用于实现rwlock的时候，可以用不同的bit来代表reader writer。
<code>FUTEX_PRIVATE_FLAG</code>，代表所有对同一个atomic操作的线程都是同一个进程，不会跨进程操作，在调用的时候，所有的调用都得带上这个flag。
优化级相关：当进程优先级高的进程，等待进程优先级低的进程的时候，这叫优先级反转，而futex的做法是，当低优先级线程持有锁时，它会<strong>临时继承</strong>等待该锁的<strong>最高优先级线程</strong>的优先级。
对于内核来说，需要futex将atomic变量设置为线程ID,用低30位。用高位来代表解锁与否。</p><h2 id=macos>macos<a hidden class=anchor aria-hidden=true href=#macos>#</a></h2><p>mac用的是pthread实现。但是速度比其它unix平台慢跑，原因是它用的是公平锁，先来先得的机制的。后面10.12才推出了非公平锁。</p><h2 id=windows>Windows<a hidden class=anchor aria-hidden=true href=#windows>#</a></h2><p>windows上的mutex叫critical setion，是可重入的。这个比较重。轻量级的有类似于linux的futex叫<code>WaitOnAdress</code>。还有SRW lock。</p><h1 id=其余的同步原语>其余的同步原语<a hidden class=anchor aria-hidden=true href=#其余的同步原语>#</a></h1><h2 id=semaphore>semaphore<a hidden class=anchor aria-hidden=true href=#semaphore>#</a></h2><p>semaphore即OS书中学到的PV操作的同步原语，wait操作会把couter减1，而signal操作会会把couter加1，如果wait遇到counter为0的时候，就会被block住，需要等到signal把counter+1才能唤醒另一个线程。实现上，一个实现是，用一个mutex来保护counter，一个convar来做wait和signal的操作，实现对线程的wait和wake操作。在linux上可以用futex来实现，这样只要用到一个atomic的u32即可实现。</p><h2 id=rcu>rcu<a hidden class=anchor aria-hidden=true href=#rcu>#</a></h2><p>rcu是一个可以用于大量的数据，多读少写的场景写的无锁数据结构，核心思想是在对一个node做修改的时候，copy一个node出去，让它先修改，其它读者会读到老的数据，然后修改完之后，把node再更新掉：
<img loading=lazy src=/images/71a5f2512aba8f699c93db94d8f5c833340b25ba.png></p><p>其中最大的问题在于最后一步，如果还有读者在引用老数据的话，需要等所有的读者都不在引用老数据才能释放掉老数据。
<a href=https://www.kernel.org/doc/html/latest/RCU/whatisRCU.html>linux rcu</a>
<a href=https://en.cppreference.com/w/cpp/header/rcu>C++ rcu</a></p><h2 id=无锁链表>无锁链表<a hidden class=anchor aria-hidden=true href=#无锁链表>#</a></h2><p><img loading=lazy src=/images/1e1b6c106f4c9a75a1b77e856690225cecc1bfb9.png></p><p>如图所示，这三步操作都可以atomic的完成。值得注意的是，可能会有多个写者来更新插入，要保证只有一个能更新成功。删除一个节点的时候，也有相同的问题，即什么时候才能释放这个节点。可以使用hazerd pointer或者引用计数等技术能实现。
<a href=https://lwn.net/Articles/610972/>https://lwn.net/Articles/610972/</a></p><h2 id=queue-based-locks>Queue-Based Locks<a hidden class=anchor aria-hidden=true href=#queue-based-locks>#</a></h2><p><img loading=lazy src=/images/1561fd62fa9bcebf1ecde4bfd114c9d9cc9cc09d.png></p><p>核心思想是，只维护一个atomic pointer，然后指向一个队列，其中指针中没有使用的位，可以用来表示锁的状态。windows里面的slim read write lock就是这么实现的。
## Parking Lot&ndash;Based Locks
parking lot 锁是对queue based lock的优化，可以把mutex优化的尽量小，即mutex只用来表示是否有锁，是否有队列，然后另外一个全局变量hashmap来表示，以adress为key，以queue为value。</p><p><img loading=lazy src=/images/cc6763ea431b423add8e200411bd92ac09f7b771.png></p><p>rust中有一个<a href=https://docs.rs/parking_lot/latest/parking_lot/>parking_lot</a>就是如此实现的。当然它还有很多优化，优化性能，否则会对hashmpa抢占很严重。</p><h2 id=sequence-lock>Sequence Lock<a hidden class=anchor aria-hidden=true href=#sequence-lock>#</a></h2><p>Sequence lock的思路是在结构中加上一个counter,当写者进行写的时候，把couter变成奇数，写完之后，再把counter变成偶数，所有的读者都可以随便读数据，但是需要比较前后的couter的数值，如果都是偶数且没有变化，则是有效，否则要重试。</p><p><img loading=lazy src=/images/2bad7c880b8f2e326db76cb77819b693d4ff6269.png></p><p><a href=https://en.wikipedia.org/wiki/Seqlock>SeqLock</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://linxy.dev/tags/rust/>Rust</a></li></ul><nav class=paginav><a class=prev href=https://linxy.dev/posts/2025-linux/><span class=title>« Prev</span><br><span>2025的Linux之旅</span>
</a><a class=next href=https://linxy.dev/posts/2024/><span class=title>Next »</span><br><span>2024总结</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Rust Atomic 笔记 on x" href="https://x.com/intent/tweet/?text=Rust%20Atomic%20%e7%ac%94%e8%ae%b0&amp;url=https%3a%2f%2flinxy.dev%2fposts%2frust-atomic%2f&amp;hashtags=rust"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rust Atomic 笔记 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flinxy.dev%2fposts%2frust-atomic%2f&amp;title=Rust%20Atomic%20%e7%ac%94%e8%ae%b0&amp;summary=Rust%20Atomic%20%e7%ac%94%e8%ae%b0&amp;source=https%3a%2f%2flinxy.dev%2fposts%2frust-atomic%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rust Atomic 笔记 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flinxy.dev%2fposts%2frust-atomic%2f&title=Rust%20Atomic%20%e7%ac%94%e8%ae%b0"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rust Atomic 笔记 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flinxy.dev%2fposts%2frust-atomic%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rust Atomic 笔记 on whatsapp" href="https://api.whatsapp.com/send?text=Rust%20Atomic%20%e7%ac%94%e8%ae%b0%20-%20https%3a%2f%2flinxy.dev%2fposts%2frust-atomic%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rust Atomic 笔记 on telegram" href="https://telegram.me/share/url?text=Rust%20Atomic%20%e7%ac%94%e8%ae%b0&amp;url=https%3a%2f%2flinxy.dev%2fposts%2frust-atomic%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rust Atomic 笔记 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Rust%20Atomic%20%e7%ac%94%e8%ae%b0&u=https%3a%2f%2flinxy.dev%2fposts%2frust-atomic%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>© <a href=https://linxy.dev>linxy&rsquo;s blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>